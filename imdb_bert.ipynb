{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb-bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe7SCMGvB3ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKUPLQOPB3W1",
        "colab_type": "code",
        "outputId": "bd953604-ae61-4264-d925-33c670828d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# download IMDb movie review dataset\n",
        "import tensorflow as tf\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\", \n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
        "    extract=True,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 5s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kolMcPssCWb4",
        "colab_type": "code",
        "outputId": "aeb008a6-4038-4969-f12c-3e3bde8919f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# set path to dataset\n",
        "import os.path\n",
        "#dataset = '/root/.keras/datasets/aclImdb'\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "print(IMDB_DATADIR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.keras/datasets/aclImdb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCHt-LV1B3QG",
        "colab_type": "code",
        "outputId": "e3392cf7-19d7-45d7-e8f2-a765fc34b75c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#load the training and validation data from the specified folder and automatically preprocess it according to BERT's requirements\n",
        "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_folder(IMDB_DATADIR, \n",
        "                                                                       maxlen=500, \n",
        "                                                                       preprocess_mode='bert',\n",
        "                                                                       train_test_names=['train', \n",
        "                                                                                         'test'],\n",
        "                                                                       classes=['pos', 'neg'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "detected encoding: utf-8\n",
            "preprocessing train...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing test...\n",
            "language: en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcXvXtYqB3C7",
        "colab_type": "code",
        "outputId": "04c6320e-e84a-41f3-ef1a-b9cdbdfbcc16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#build the model and learner\n",
        "model = text.text_classifier('bert', (x_train, y_train), preproc=preproc)\n",
        "learner = ktrain.get_learner(model,train_data=(x_train, y_train), val_data=(x_test, y_test), batch_size=6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 500\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JbVC8O8F96r",
        "colab_type": "text"
      },
      "source": [
        "Now we train the model. Because of the size of teh sample (25000), it takes quite long time, therefore we have already trained and saved the weights in imdb_bert.h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daIQCBZgFz_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learner.fit_onecycle(2e-5, 1)\n",
        "\n",
        "# model.save('imdb_bert.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDHDgXFhBTmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the weights\n",
        "learner.load_model('imdb_bert.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S2YCeJfBWAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build the predictor\n",
        "predictor = ktrain.get_predictor(learner.model, preproc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrpkZBpeFAmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generate some texts\n",
        "data = [ 'This movie was horrible! The plot was boring. Acting was okay, though.',\n",
        "         'The film really sucked. I want my money back.',\n",
        "        'The plot had too many holes.',\n",
        "        'What a beautiful romantic comedy. 10/10 would see again!',\n",
        "         ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo-2KgiBFGQM",
        "colab_type": "code",
        "outputId": "a5b63f8f-859e-4192-db88-e3e62228914d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#get the prediction\n",
        "predictor.predict(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg', 'neg', 'neg', 'pos']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}